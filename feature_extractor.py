import glob
from os.path import join, dirname, realpath, basename
from pickle import loads
from csv import writer, QUOTE_MINIMAL
from optparse import OptionParser

from multiprocessing import Queue, Pool, cpu_count

from androguard.misc import *

from log import log

import pickle


data_queue = Queue()


def analyze_apk_file(apk_file_path: str):
    """Analyze APK file."""
    a, _, analysis = AnalyzeAPK(apk_file_path)
    return a.get_permissions(), analysis


def extract_feature(file):
    file_name = basename(file)
    log().info("analyzing file: {}".format(file_name))
    permissions, analysis = analyze_apk_file(file)
    res = {}

    for feature in features:
        res.setdefault(feature, 0)

    # permissions
    for permission in permissions:
        if permission in res:
            res[permission] = 1

    # method call
    methods = analysis.get_methods()
    call_count = {}

    with open('classifier/apicall.pkl', 'rb') as file_object:
        data = pickle.load(file_object)

    for method in methods:
        if method.is_android_api():
            info = method.get_method()
            name = "{}.{}".format(info.get_class_name()[1:-1].replace('/', '.'), info.name)
            if name in data:
                for permission in data[name]:
                    if permission in call_count:
                        call_count[permission] += 1
                    else:
                        call_count[permission] = 1

    for key in call_count.keys():
        count = call_count[key]
        name = "{}/method".format(key)
        res[name] = count

    # make feature tables
    p = [0] * len(features)
    for idx in range(len(features)):
        p[idx] = res[features[idx]]

    log().info("Successfully extract feature from {} file".format(file_name))

    return p, file_name


def process_file(data):
    global data_queue
    file, file_type = data
    p, file_name = extract_feature(file)
    p.insert(0, file_name)
    p.insert(1, file_type)

    data_queue.put(p)


if __name__ == '__main__':
    opt_parser = OptionParser()
    opt_parser.set_defaults(inmemory=False, debug=False, UseLocalTimezone=True, UseGUI=False)
    opt_parser.add_option('-t', '--train-data-path',
                          dest='train_data_path',
                          help='Input train data path')

    options, args = opt_parser.parse_args()
    if options.train_data_path is None:
        opt_parser.print_help()
        exit(-1)

    current_module_path = dirname(realpath(__file__))
    with open(join(current_module_path, 'classifier/permissions.pkl'), 'rb') as file_object:
        features = loads(file_object.read())

    with open(join(current_module_path, 'classifier/apicall_header.pkl'), 'rb') as file_object:
        features += loads(file_object.read())

    log().info('load {} features'.format(len(features)))

    # set train csv file
    csv_file_object = open('train.csv', 'w')
    csv_writer = writer(csv_file_object, delimiter=',', quoting=QUOTE_MINIMAL)

    csv_headers = features.copy()
    csv_headers.insert(0, 'name')
    csv_headers.insert(1, 'type')

    csv_writer.writerow(csv_headers)

    malware_data_path = join(options.train_data_path, '1-malware')

    pool = Pool(processes=cpu_count() * 2)
    pool.map(
        process_file,
        [[filepath, 1] for filepath in glob.glob('{}/*.vir'.format(malware_data_path))[:10]])

    normal_data_path = join(options.train_data_path, '0-normal')

    pool.map(
        process_file,
        [[filepath, 0] for filepath in glob.glob('{}/*.vir'.format(normal_data_path))[:10]])

    while not data_queue.empty():
        csv_writer.writerow(data_queue.get())

    log().info('Successfully done:-')
    csv_file_object.close()
