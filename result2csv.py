import sys
from os import mkdir
from os.path import abspath, join, dirname, exists
from optparse import OptionParser
from collections import Counter

from sklearn.cluster import KMeans

import csv
import numpy as np
from log import log


project_root_folder = abspath(join(dirname(__file__)))
if project_root_folder not in sys.path:
    sys.path.insert(0, project_root_folder)

_default_minimum_cluster = 2
_default_maximum_cluster = 3


def set_dataset(row):
    return {
        'name': row[0],
        'type': int(row[1]),
        'feature': np.array(row[2:])
    }


def set_morb_name_and_features(dataset):
    morb_name_and_features = {}
    for idx, row in enumerate(dataset.items()):
        morb_name_and_features[idx] = {'name': row[1]['name'],
                                       'feature': row[1]['feature']}
    return morb_name_and_features


def export_result(file_object, result, tag):
    # filename / feature
    for fn_ft in result:
        file_object.write('{}, {}, {}\n'.format(fn_ft['name'],
                                                ' '.join(fn_ft['feature'].tolist()),
                                                tag))


def load_dataset(train_file_path):
    dataset = {}
    with open(train_file_path) as file_object:
        reader = csv.reader(file_object, delimiter=',', quoting=csv.QUOTE_MINIMAL)
        for index, row in enumerate(reader):
            if index > 0:
                dataset[index] = set_dataset(row)
    # set malware or normal apk file name
    morb_name = (np.array([row[1]['name'] for row in dataset.items()]))
    log().debug("morb_name = {}".format(morb_name))
    # set feature
    feature = (np.array([row[1]['feature'] for row in dataset.items()]))
    log().debug("Feature={}".format(feature))
    # set name and features
    morb_name_and_features = set_morb_name_and_features(dataset)
    log().debug("morb_name_and_features = {}".format(morb_name_and_features))
    # set label
    label = (np.array([row[1]['type'] for row in dataset.items()]))
    log().debug("Label {}".format(label))

    return morb_name, feature, morb_name_and_features, label


def main(train_file, minimum_cluster, maximum_cluster, output_dir):
    morb_name, feature, morb_name_and_features, label = load_dataset(train_file)
    best_cluster = {'c_number': 0, 'precision': 0}

    for i in range(minimum_cluster, maximum_cluster+1):
        tp = 0  # true-positive
        fp = 0  # false-positive
        tn = 0  # true-negative
        fn = 0  # true-positive
        c_result = {}
        c_result_name = {}

        # output file write
        cluster_file_name = join(output_dir, '{}_cluster_reslt.csv'.format(i))
        file_object = open(cluster_file_name, 'w')
        kmeans = KMeans(n_clusters=i, random_state=0).fit(feature)
        labels = kmeans.labels_.tolist()
        file_object.write("Name, Features, True_False \n")

        # clustering result check using dictionary
        for j in range(len(labels)):
            if labels[j] in c_result:
                c_result[labels[j]].append(label[j])
                c_result_name[labels[j]].append(morb_name_and_features[j])
            else:
                c_result[labels[j]] = [label[j]]
                c_result_name[labels[j]] = [morb_name_and_features[j]]
        log().debug(c_result_name)
        morb = 0
        for k in range(i):
            try:
                each_c = Counter(c_result[k])  # each cluster bucket
                morb = max(each_c, key=each_c.get)  # malware or benign in each cluster
                if morb == 0:
                    tp += each_c[0]
                    fp += each_c[1]
                # if morb is 1
                else:
                    tp += each_c[1]
                    fp += each_c[0]
            except Exception as e:
                log().error("{}, {}".format(type(e),
                                            e))
                pass
            log().info("Make Result File to {}".format(cluster_file_name))
        if morb == 0:
            export_result(file_object, c_result_name[0], "True")
            export_result(file_object, c_result_name[1], "False")
        else:
            export_result(file_object, c_result_name[1], "True")
            export_result(file_object, c_result_name[0], "False")
        file_object.close()
        precision = tp / (fp + tp)

        log().info("Running result of {} cluster".format(i))
        log().info("tp: {} / fp: {}".format(tp, fp))
        log().info("%d cluster's Precision: %0.4f" %(i, precision))

        if best_cluster['precision'] < precision:
            best_cluster['precision'] = precision
            best_cluster['c_number'] = i

    log().info("="*58)
    log().info("Best of the Best cluster: {}".format(best_cluster['c_number']))
    log().info("Precision: {}".format(best_cluster['precision']))
    log().info("=" * 58)


def verify_options(options):
    if options.minimum_cluster is None:
        minimum_cluster = _default_minimum_cluster
    else:
        minimum_cluster = options.minimum_cluster
    if options.maximum_cluster is None:
        maximum_cluster = _default_maximum_cluster
    else:
        maximum_cluster = options.maximum_cluster
    if options.output_dir is None:
        output_file = join(project_root_folder, 'exported')
    else:
        output_file = options.output_dir
    return minimum_cluster, maximum_cluster, output_file


if __name__ == '__main__':

    opt_parser = OptionParser()
    opt_parser.add_option(
        '-f', '--train_file_path', dest='train_file',
        help='csv input feature table.')
    opt_parser.add_option(
        '--min', dest='minimum_cluster', type=int,
        help='the number of minimum cluster (default: 2)')
    opt_parser.add_option(
        '--max', dest='maximum_cluster', type=int,
        help='the number of maximum cluster (default: 3)')
    opt_parser.add_option(
        '--output', dest='output_dir',
        help='.csv output filename. silhouette result')

    options, _ = opt_parser.parse_args()
    if options.train_file is None:
        opt_parser.print_help()
        exit(-1)
    minimum_cluster, maximum_cluster, output_dir = verify_options(options)
    if exists(output_dir) is False:
        mkdir(output_dir)
    main(options.train_file, minimum_cluster, maximum_cluster, output_dir)
