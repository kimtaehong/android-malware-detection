from optparse import OptionParser

import csv
import numpy as np
from collections import Counter

from sklearn.cluster import KMeans

def set_dataset(row):
    return {
        'name': row[0],
        'type': int(row[1]),
        'feature': np.array(row[2:])
    }


def main(train_file, minimum_cluster, maximum_cluster, output_file):
    minimum_cluster = 10
    maximum_cluster = 11


    dataset = {}
    c_result = {}#clustering result e.g., {2: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
     # 3: [1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 1: [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 0: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 4: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 6: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
     # 8: [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0], 5: [1, 1, 1, 0, 1], 9: [1, 1, 1, 1], 7: [1, 0], 10: [1]}

    with open(train_file, 'r') as csvfile:
        reader = csv.reader(csvfile, delimiter=',', quoting=csv.QUOTE_MINIMAL)
        for index, row in enumerate(reader):
            if index > 0:
                dataset[index] = set_dataset(row)
                # break
    feature = (np.array([row[1]['feature'] for row in dataset.items()]))
    label = (np.array([row[1]['type'] for row in dataset.items()]))

    for i in range(minimum_cluster, maximum_cluster+1):
        tp = 0  # true-positive
        fp = 0  # false-positive
        tn = 0  # true-negative
        fn = 0  # true-positive

        kmeans = KMeans(n_clusters=i, random_state=0).fit(feature)
        result = kmeans.labels_.tolist()

        #clustering result check using dicitonary
        for j in range(0,len(result)):
            if(result[j] in c_result):
                c_result[result[j]].append(label[j])
            else:
                c_result[result[j]]=[label[j]]

        print(c_result)

        for k in range(0,i):
            print("k=%d" %k)

            each_c = Counter(c_result[k]) # each cluster bucket
            morb = max(each_c, key=each_c.get) #malware or benign in each cluster     
            print("morb=%d" %morb)
            if morb is 0:
                tp += each_c[0]
                print("tp=%d" %tp)
                fp += each_c[1]
                print("fp=%d" %fp)

            else:#if morb is 1
                tp += each_c[1]
                print("tp=%d" %tp)
                fp += each_c[0]
                print("fp=%d" %fp)

        print("Precision=%d" %(tp/(fp+tp)))

        # if normal_count <= malware_count:
        #     # malware group
        #     tp += malware_count
        #     fp += normal_count
        # else:
        #     # normal group
        #     tn += normal_count
        #     fn += malware_count

        # print(tp)
        # print(fp)

if __name__ == '__main__':

    opt_parser = OptionParser()
    opt_parser.add_option(
        '-c', '--csv', dest='train_file',
        help='csv input feature table.')
    opt_parser.add_option(
        '--min', dest='minimum_cluster',
        help='the number of minimum cluster (default: 2)')
    opt_parser.add_option(
        '--max', dest='maximum_cluster',
        help='the number of maximum cluster (default: 3)')
    opt_parser.add_option(
        '--output', dest='output_file',
        help='.csv output filename. silhouette result')

    options, _ = opt_parser.parse_args()

    main(options.train_file, options.minimum_cluster, options.maximum_cluster, options.output_file)
