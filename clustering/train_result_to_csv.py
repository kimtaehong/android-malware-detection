from os import mkdir
from os.path import exists, join, isdir, dirname, realpath
from optparse import OptionParser
from collections import Counter

from sklearn.cluster import KMeans

from csv import writer, reader, QUOTE_MINIMAL
import numpy as np

from context import *
from clustering.log import log


_default_n_cluster = 2
_result_csv_header = ['ClusterNumber', 'FileName', 'Features', 'label', 'IsMalware']


def set_dataset(row):
    return {
        'name': row[0],
        'type': int(row[1]),
        'feature': np.array(row[2:])
    }


def set_morb_name_and_features(dataset):
    morb_name_and_features = {}
    for idx, row in enumerate(dataset.items()):
        morb_name_and_features[idx] = {'name': row[1]['name'],
                                       'feature': row[1]['feature'],
                                       'type': row[1]['type']}
    return morb_name_and_features


def export_result(csv_writer, cluster_number, is_morb, result, result_name):
    # filename / feature
    for idx, tp_or_fp in enumerate(result):
        if is_morb == 0 and tp_or_fp == 0:
            tag = 'True'
        elif is_morb == 1 and tp_or_fp == 1:
            tag = 'True'
        else:
            continue
        csv_writer.writerow([cluster_number,
                             result_name[idx]['name'],
                             ' '.join(result_name[idx]['feature'].tolist()),
                             tag,
                             result_name[idx]['type']])


def load_dataset(train_file_path):
    dataset = {}
    with open(train_file_path) as file_object:
        rows = reader(file_object, delimiter=',', quoting=QUOTE_MINIMAL)
        for index, row in enumerate(rows):
            if index > 0:
                dataset[index] = set_dataset(row)
    # set malware or normal apk file name
    morb_name = (np.array([row[1]['name'] for row in dataset.items()]))
    log().debug("morb_name = {}".format(morb_name))
    # set feature
    feature = (np.array([row[1]['feature'] for row in dataset.items()]))
    log().debug("Feature={}".format(feature))
    # set name and features
    morb_name_and_features = set_morb_name_and_features(dataset)
    log().debug("morb_name_and_features = {}".format(morb_name_and_features))
    # set label
    label = (np.array([row[1]['type'] for row in dataset.items()]))
    log().debug("Label {}".format(label))

    return morb_name, feature, morb_name_and_features, label


def main(train_file, n_cluster, output_dir):
    morb_name, feature, morb_name_and_features, label = load_dataset(train_file)
    best_cluster = {'c_number': 0, 'precision': 0}

    for i in range(n_cluster, n_cluster+1):
        tp = 0  # true-positive
        fp = 0  # false-positive
        tn = 0  # true-negative
        fn = 0  # true-positive
        c_result = {}
        c_result_name = {}

        # output file write
        cluster_file_name = join(output_dir, '{}_cluster_result.csv'.format(i))
        file_object = open(cluster_file_name, 'w')
        csv_writer = writer(file_object, delimiter=',', quoting=QUOTE_MINIMAL)
        kmeans = KMeans(n_clusters=i, random_state=0).fit(feature)
        labels = kmeans.labels_.tolist()
        csv_writer.writerow(_result_csv_header)

        # clustering result check using dictionary
        for j in range(len(labels)):
            if labels[j] in c_result:
                c_result[labels[j]].append(label[j])
                c_result_name[labels[j]].append(morb_name_and_features[j])
            else:
                c_result[labels[j]] = [label[j]]
                c_result_name[labels[j]] = [morb_name_and_features[j]]
        log().debug(c_result_name)
        for k in range(i):
            try:
                each_c = Counter(c_result[k])  # each cluster bucket
                morb = max(each_c, key=each_c.get)  # malware or benign in each cluster
                if morb == 0:
                    tn += each_c[0]
                    fp += each_c[1]
                # if morb is 1
                else:
                    tp += each_c[1]
                    fn += each_c[0]
                export_result(csv_writer, k, morb, c_result[k], c_result_name[k])
            except Exception as e:
                log().error("{}, {}".format(type(e),
                                            e))
                pass
        log().info("Make Result File to {}".format(cluster_file_name))
        file_object.close()
        # accuracy
        accuracy = (tp + tn) / (fp + tp + fn + tn)

        log().info("Running result of {} cluster".format(i))
        log().info("tn: {}, fn: {} / tp: {}, fp: {}".format(tn,
                                                            fn,
                                                            tp,
                                                            fp))
        log().info("%d cluster's Precision: %0.4f" %(i, accuracy))

        if best_cluster['precision'] < accuracy:
            best_cluster['precision'] = accuracy
            best_cluster['c_number'] = i

    log().info("="*58)
    log().info("Best of the Best cluster: {}".format(best_cluster['c_number']))
    log().info("Precision: {}".format(best_cluster['precision']))
    log().info("=" * 58)


def verify_options(options):
    current_module_path = dirname(realpath(__file__))
    if options.n_cluster is None:
        n_cluster = _default_n_cluster
    else:
        n_cluster = options.n_cluster
    if options.output_dir is None:
        output_dir = join(current_module_path, 'exported')
    else:
        output_dir = options.output_dir
    return n_cluster, output_dir


if __name__ == '__main__':
    opt_parser = OptionParser()
    opt_parser.add_option(
        '-f', '--train_file_path', dest='train_file',
        help='csv input feature table.')
    opt_parser.add_option(
        '-k', '--cluster_number', dest='n_cluster', type=int,
        help='cluster number (default: 2)')
    opt_parser.add_option(
        '--output', dest='output_dir',
        help='.csv output filename. silhouette result')

    options, _ = opt_parser.parse_args()
    if options.train_file is None:
        opt_parser.print_help()
        exit(-1)
    n_cluster, output_dir = verify_options(options)
    if isdir(output_dir) is False:
        opt_parser.print_help()
        exit(-1)
    if exists(output_dir) is False:
        mkdir(output_dir)
    main(options.train_file, n_cluster, output_dir)
